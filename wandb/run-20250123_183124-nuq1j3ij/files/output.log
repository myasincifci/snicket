/home/yasin/miniforge3/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/yasin/miniforge3/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/yasin/miniforge3/lib/python3.10/site-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
  | Name      | Type              | Params
------------------------------------------------
0 | model     | ResNet            | 11.2 M
1 | train_acc | BinaryAccuracy    | 0
2 | val_acc   | BinaryAccuracy    | 0
3 | loss_fn   | BCEWithLogitsLoss | 0
------------------------------------------------
11.2 M    Trainable params
0         Non-trainable params
11.2 M    Total params
44.708    Total estimated model params size (MB)
Epoch 0:   0%|                                                                                                                                             | 0/110 [00:00<?, ?it/s]
/home/yasin/miniforge3/lib/python3.10/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)


























Epoch 2: 100%|█| 110/110 [00:15<00:00,  6.92it/s, v_num=j3ij, train/loss_step=0.0983, train/acc_step=0.953, val/loss=0.270, val/acc=0.896, train/loss_epoch=0.153, train/acc_epoch=








Epoch 3: 100%|█| 110/110 [00:15<00:00,  6.98it/s, v_num=j3ij, train/loss_step=0.0395, train/acc_step=0.977, val/loss=0.924, val/acc=0.744, train/loss_epoch=0.0883, train/acc_epoch








Epoch 4: 100%|█| 110/110 [00:15<00:00,  6.95it/s, v_num=j3ij, train/loss_step=0.273, train/acc_step=0.907, val/loss=0.500, val/acc=0.862, train/loss_epoch=0.0717, train/acc_epoch=








Epoch 5: 100%|█| 110/110 [00:15<00:00,  7.00it/s, v_num=j3ij, train/loss_step=0.0955, train/acc_step=0.977, val/loss=1.020, val/acc=0.769, train/loss_epoch=0.051, train/acc_epoch=








Epoch 6: 100%|█| 110/110 [00:15<00:00,  6.96it/s, v_num=j3ij, train/loss_step=0.019, train/acc_step=1.000, val/loss=0.529, val/acc=0.838, train/loss_epoch=0.046, train/acc_epoch=0








Epoch 7: 100%|█| 110/110 [00:15<00:00,  6.97it/s, v_num=j3ij, train/loss_step=0.0123, train/acc_step=1.000, val/loss=0.463, val/acc=0.860, train/loss_epoch=0.0443, train/acc_epoch


















Epoch 9: 100%|█| 110/110 [00:15<00:00,  6.96it/s, v_num=j3ij, train/loss_step=0.272, train/acc_step=0.907, val/loss=0.849, val/acc=0.820, train/loss_epoch=0.0185, train/acc_epoch=
Validation DataLoader 0:  88%|██████████████████████████████████████████████████████████████████████████████████████████████████████▍              | 14/16 [00:01<00:00, 10.48it/s]

`Trainer.fit` stopped: `max_epochs=10` reached.